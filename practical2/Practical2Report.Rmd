---
title: "Practical Report 2"
output:
   pdf_document: 
     keep_tex: true
     fig_caption: yes
     highlight: monochrome
   html_document:
    df_print: paged
    code_folding: hide
fontsize: 12pt
---

```{r setup, include = FALSE}
require(knitr)
pdf_doc <- knitr::is_latex_output()
if (pdf_doc) {opts_chunk$set(echo=FALSE, fig.align="center", out.width="70%")} else {opts_chunk$set(echo=TRUE)}
```


# Acceptable residual plots

In this practical we will explore simulated data to illustrate residual diagnostics which are part of the linear modelling process. Residual plots allows us to judge the appropriateness of the assumption of linearity and homoscedasticity. 

<!--- Section 1, Question 1 --->


```{r, Data1}
# Set a seed to make simulations reproducible
set.seed(2302) 
# Dataset 1
x <- 1:100
y <- 3 + 0.5*x + rnorm(100, 0, 2)
```

We produce an artificial dataset in which the explanatory variable takes values from ...

The response observations are simulated from the linear model ...


<!--- Section 1, Question 2 --->

```{r, SLR1, fig.cap=""}
# Fit a simple linear regression
model1 <- lm(y ~ x)
# Scatterplot with line of best fit
plot(x, y)
abline(model1, col="blue")
# Coefficients of fitted model
coef(model1)
```

<!--- Comment on how the estimated parameters compared to the ones used to simulate the data. --->

The line of best fit has intercept `r round(coef(model1)[1],2)` and slope ...


<!--- Section 1, Question 3 --->
```{r Residual1, fig.cap=""}
# Residual plot for model 1
plot(model1, 1)
```

<!--- Comment on the residual plot-->

<!--- Section 1 Question 4 --->

Next, we sample Dataset 2  ... 

```{r, LinearModel2, fig.show="hold", out.width="49%", fig.cap="Left: Right:"}
# Dataset 2
set.seed(1184) 
x2 <- 1:20
y2 <- 3 + 0.5*x2 + rnorm(20, 0, 1)
# Fit linear model
model2 <- lm(y2 ~ x2)
# Produce scatterplot with line of best fit
plot(y2 ~ x2)
abline(model2, col="blue")
# Produce residual plot 
plot(model2, 1) 
```

<!--- With fewer datapoints, is it harder or easier to assess a residual plot?--->

# Unacceptable residual plots

The figure below shows the scatterplot of a dataset sampled from the model
\[ Y_j \quad = \quad 10 + \frac{1}{2}x_j + \epsilon_j,\]
where $x_j = j$ and $\epsilon_j \sim {\cal N}(0, x_j)$ for $j=1, \ldots, 100$. Furthermore, the errors $\epsilon_1, \ldots, \epsilon_{100}$ are independent. We fitted a simple linear regression model to the data and added the fitted line to the scatterplot.

<!--- Section 2 Question 1 --->

```{r, data3, fig.cap=""}
# Dataset 3
set.seed(1285)
x3 <- seq(1, 100, length.out=100)
y3 <- 10 + 0.5*x3 + rnorm(100, 0, sqrt(x3))
# Produce a scatterplot

# Fit a simple linear regression model and add line of best fit to the plot

```

From the model equations we note that ...

We expect the residual plot ...

```{r ResidualPlot1, fig.cap=""}
# Residual Plot 

```


<!--- Section 1, Question 2 --->
<!--- Improve the model so that the model assumptions become reasonable --->




<!--- Section 2 Question 3 --->
<!--- Dataset 4--->

Our final artificial dataset is sampled from the model ...

```{r, data4,  fig.cap="Scatterplot of Dataset 4."}
# Dataset 4
set.seed(1066)
x <- seq(0.25, 25, by=0.25)
y <- 100 - 20*x + x^2 + rnorm(100, 0, 20)
# Produce a scatterplot of the dataset

```
<!--- Comment on the plot --->


<!--- Section 2, Question 4 --->
<!--- Residual plots of the simple linear regression model and the quadratic regression model --->

```{r, ResidualPlots4, fig.show="hold", out.width="49%", fig.cap="Left: Right:",  }

# Fit simple linear regression model and produce residual plot 

# Fit quadratic regression model and produce residual plot

```

<!--- Comment on the residual plots --->

<!-- Section 2, Question 5 and 6: Plotting the quadratic regression model --->

We make use of the  function `quadraticPlot` to visualise the quadratic regression model. 
```{r, Quadratic, echo=TRUE}

quadraticPlot <- function(x,y){
  # Produce a scatterplot of the data
  plot(x, y, xlab="x", ylab="y", main="Scatterplot")
  # Fit a quadratic regression model
  m <- lm(y ~ x + I(x^2))
  # Create a vector ax of length 101 
  # spanning the range of the explanatory variable
  ax<-seq(min(x), max(x), length.out=101)
  # predict the response for each value in ax
  fitted.curve<-predict(m, newdata=list(x=ax))
  # Fit a curve through the predicted response values and 
  # add to this to the plot
  lines(ax, fitted.curve, col="navy", lwd=2) 
}
```

```{r data3quadratic, fig.cap= ""}
# Apply the quadraticPlot function to the quadratic regression model fitted earlier

```

<!--- Comment on the plot --->

<!--- Section 2, Question 7 --->


